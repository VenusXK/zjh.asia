# Hadoop实验基础部分(2节点)

[[TOC]]

## AWS实例初始化

### 创建实例

在 AWS 设立三台实例，配置均如下：

- **实例的数量**：2
- **Software Image (AMI)**：Canonical, Ubuntu, 22.04 LTS, ... ami-0fc5d935ebf8bc3bc
- **Virtual server type (instance type)**：t2.medium
- **Firewall (security group)**：launch-wizard-1
- **Storage (volumes)**：1 volume(s) - 15 GiB

创建后，显示：

::: warning ✓ 成功
已成功启动实例 (i-096344e491bea0fa9, i-006b90bfdb5e7849c, i-09640f1c3d9f47508)
:::

对实例重新命名，依次为 `master-node`、`slave-node-1`、`slave-node-2`。

使用 ssh 连接到实例，获取实例公有 IPv4 DNS，如下：

- `master-node: ec2-54-209-223-68.compute-1.amazonaws.com`
- `slave-node-1: ec2-3-82-200-200.compute-1.amazonaws.com`
- `slave-node-2: ec2-54-161-114-48.compute-1.amazonaws.com`

输入 ssh 命令进行连接，如下：

```cmd
ssh -i zjh-hadoop.pem ubuntu@ec2-54-209-223-68.compute-1.amazonaws.com
```

获取到远程终端，如下：

```cmd
The authenticity of host 'ec2-54-209-223-68.compute-1.amazonaws.com (54.209.223.68)' can't be established.
ED25519 key fingerprint is SHA256:7trJrhD1hwRXOmFlBvRxpdBihiM9w5OAh64643TCGfE.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
```

输入 `yes`，继续连接，如下：

```cmd
Warning: Permanently added 'ec2-54-209-223-68.compute-1.amazonaws.com' (ED25519) to the list of known hosts.
Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-1012-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  System information as of Thu Dec 14 07:45:28 UTC 2023

  System load:  0.0                Processes:             106
  Usage of /:   10.8% of 14.36GB   Users logged in:       0
  Memory usage: 5%                 IPv4 address for eth0: 172.31.91.103
  Swap usage:   0%

Expanded Security Maintenance for Applications is not enabled.

0 updates can be applied immediately.

Enable ESM Apps to receive additional future security updates.
See https://ubuntu.com/esm or run: sudo pro status


The list of available updates is more than a week old.
To check for new updates run: sudo apt update


The programs included with the Ubuntu system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by
applicable law.

To run a command as administrator (user "root"), use "sudo <command>".
See "man sudo_root" for details.
```

显示成功连接到远程终端，如下：

```bash
ubuntu@ip-172-31-91-103:
```

### 下载并使用 MobaXterm

MobaXterm 是一个远程计算的终端工具，可以在 Windows 上使用，可以同时显示多个终端，并进行同时操作，十分方便。

填写对应公网 IPv4 地址，用户名为 `ubuntu`，在 `Advanced SSH settings` 中选择 `Use private key`，选择本地 ssh 的 pem 文件，点击确定。

点击按钮菜单栏的 `MuliExec` 按钮，进入多窗口同时执行命令的模式。

## 服务器环境初始化

### 新建 hadoop 用户

登陆实例后，默认用户为 `ubuntu`，首先需要创建一个 `hadoop` 用户。

```shell
sudo useradd -m hadoop -s /bin/bash   # 增加 hadoop用户
sudo passwd hadoop  			        # 设置密码，需要输入两次
# 设置密码为 hadoop
sudo adduser hadoop sudo  		    # 为 hadoop 用户增加管理员权限
su hadoop   				            # 切换到 hadoop 用户，需要输入密码
sudo apt-get update  			        # 更新 apt 源
```


### 安装 Java 环境（JDK版本不匹配，正确安装见 #[重新安装 Java 环境](#重新安装-java-环境))

Hadoop 依赖于 Java 环境，所以接下来需要先安装 JDK，安装 `x64 Compressed Archive | 135.33 MB | jdk-8u391-linux-x64.tar.gz` 版本：`x64 Compressed Archive	188.09 MB | https://download.oracle.com/java/21/latest/jdk-21_linux-x64_bin.tar.gz (sha256)`

在 hadoop 目录使用 wget 下载 java：

```shell
wget https://download.oracle.com/java/21/latest/jdk-21_linux-x64_bin.tar.gz
```

使用 ls 命令查看目录下文件，如下：

```shell
hadoop@ip-172-31-82-238:~ls
jdk-21_linux-x64_bin.tar.gz
```

使用 tar 命令解压文件，如下：

```shell
sudo tar -zxf jdk-21_linux-x64_bin.tar.gz -C /usr/lib/   # 把JDK文件解压到/usr/lib目录下
sudo mv /usr/lib/jdk-21.0.1 /usr/lib/java # 重命名java文件夹
vim ~/.bashrc # 配置环境变量，貌似EC2只能使用 vim
```

添加如下内容：

```shell
export JAVA_HOME=/usr/lib/java
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
```

重载配置文件，如下：

```shell
source ~/.bashrc   # 让配置文件生效
java -version    # 查看 Java 是否安装成功
```

## 配置节点连接

### 配置节点之间互通

修改各个节点的主机名，执行 `sudo vim /etc/hostname` ，在 master 节点上将 `ip-xxx-xx-xx-xx` 变更为 `master` 或 `slavex` ，其他节点类似，如下所述：

原始文件如下:

```shell
ip-172-31-91-103
```

```shell
ip-172-31-92-124
```

```shell
ip-172-31-82-238
```

修改后文件如下：

```shell
master
```

```shell
slave1
```

```shell
slave2
```

执行 `sudo vim /etc/hosts` 修改自己所用节点的IP映射，注意这里的 IP 地址是上文所述的私有 IP。

```shell
172.31.91.103 master
172.31.92.124 slave1
172.31.82.238 slave2
```

完成后重启一下，在进入 hadoop 用户，能看到机器名的变化。

对于 EC2 实例来说，还需要配置安全组，使实例能够互相访问，设置安全组CIDR块为 `172:31::`，安全组描述为 `所有流量`，返回如下信息：

::: danger ✗ 新建
CIDR block 172:31:: is malformed
:::

修改CIDR块为 `172.31.0.0/16`，同时需要修改描述为纯英文，否则会报错，修改为 `hadoop-in` ，点击"保存规则"，返回如下信息：

::: warning ✓ 成功
已在安全组上成功修改了入站安全组规则 (sg-0e30e2ad86abccce5 | launch-wizard-1) 
:::

三台实例都设置完成后，需要互相 ping 一下测试。

```
ping master -c 3
ping slave1 -c 3
ping slave2 -c 3
```

ping 通示例
```shell 
PING master (172.31.91.103) 56(84) bytes of data.
64 bytes from master (172.31.91.103): icmp_seq=1 ttl=64 time=0.023 ms
64 bytes from master (172.31.91.103): icmp_seq=2 ttl=64 time=0.037 ms
64 bytes from master (172.31.91.103): icmp_seq=3 ttl=64 time=0.035 ms

--- master ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2053ms
rtt min/avg/max/mdev = 0.023/0.031/0.037/0.006 ms
```

### 配置节点 SSH 互信

接下来安装 SSH server， SSH 是一种网络协议，用于计算机之间的加密登录。安装完 SSH 后，要让 master 节点可以无密码 SSH 登陆到各个 slave 节点上。

在master节点上执行如下命令：

```shell
sudo apt-get install openssh-server
ssh localhost # 使用 ssh 登陆本机，需要输入 yes 和 密码
exit # 退出刚才的 ssh localhost, 注意不要退出hadoop用户
cd ~/.ssh/ # 若没有该目录，请先执行一次ssh localhost
```

本地生成的一对秘钥，私钥 `~/.ssh/id_rsa` 和公钥 `~/.ssh/id_rsa.pub` 。公钥 `~/.ssh/id_rsa.pub` 应该保存在远程服务器端已认证的秘钥文件内 `~/.ssh/authorized_keys`。

```shell
ssh-keygen -t rsa # 利用 ssh-keygen 生成密钥，会有提示，疯狂按回车就行
cat ./id_rsa.pub >> ./authorized_keys # 将密钥加入授权
```

接下来将密钥传输到节点

``` shell
scp ~/.ssh/id_rsa.pub slave1:/home/hadoop/ # 将密钥传到 slave1 节点
scp ~/.ssh/id_rsa.pub slave2:/home/hadoop/ # 将密钥传到 slave2 节点
```

执行上述命令，显示 ` hadoop@slave1: Permission denied (publickey). lost connection`，考虑远程主机禁用了 ssh 密码登录权限。

登录目标机器，打开超级管理员权限，打开 `/etc/ssh/sshd_config` ,按照如下操作：

```shell
sudo vim /etc/ssh/sshd_config
```

修改 `PasswordAuthentication no` 为：`PasswordAuthentication yes`。

然后重启服务，执行 `service sshd restart`。


选择认证的用户，选择hadoop，如下：

```shell
hadoop@master:/home/ubuntuservice sshd restart
==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-units ===
Authentication is required to restart 'ssh.service'.
Multiple identities can be used for authentication:
 1.  Ubuntu (ubuntu)
 2.  hadoop
Choose identity to authenticate as (1-2): 2
Password:
==== AUTHENTICATION COMPLETE ===
```

重新执行ssh证书的传输，如下：

```shell
hadoop@master:/home/ubuntuscp ~/.ssh/id_rsa.pub slave1:/home/hadoop/
hadoop@slave1's password:
id_rsa.pub                             100%  567   692.3KB/s   00:00
```

接着在 slave1 和 slave2 节点上，将 ssh 公匙加入授权：

```shell
mkdir ~/.ssh       # 如果不存在该文件夹需先创建，若已存在则忽略
cat ~/id_rsa.pub >> ~/.ssh/authorized_keys
```

在 master 节点上就可以无密码 SSH 到各个 slave 节点了，可在 master 节点上执行如下命令进行检验，如下图所示变为 slave1 了，再按 exit 可退回到 master。

至此网络配置完成。

## Hadoop 搭建

### 安装并配置 Hadoop

去到镜像站 https://archive.apache.org/dist/hadoop/core/ 下载，下载 `hadoop-2.8.4.tar.gz`，注意不是`hadoop-2.8.4-src.tar.gz` 。

```shell
wget https://archive.apache.org/dist/hadoop/core/hadoop-2.8.4/hadoop-2.8.4.tar.gz
```

在 master 节点上执行：

```shell
sudo tar -zxf ./hadoop-2.8.4.tar.gz -C /usr/lib # 解压到/usr/lib中
cd /usr/lib/
sudo mv ./hadoop-2.8.4/ ./hadoop # 将文件夹名改为hadoop
sudo chown -R hadoop ./hadoop # 修改文件权限
```

将 hadoop 目录加到环境变量，这样就可以在任意目录中直接使用 hadoop、hdfs 等命令。执行 `vim ~/.bashrc` ，加入一行：

```shell
export PATH=$PATH:/usr/lib/hadoop/bin:/usr/lib/hadoop/sbin
```

保存后执行 `source ~/.bashrc` 使配置生效。

完成后开始修改 Hadoop 配置文件(这里也顺便配置了 Yarn)，先执行 `cd /usr/lib/hadoop/etc/hadoop` ，共有 6 个需要修改：

- hadoop-env.sh
- slaves
- core-site.xml
- hdfs-site.xml
- mapred-site.xml
- yarn-site.xml 

#### 1. 修改 `hadoop-env.sh`

文件 hadoop-env.sh 中把 `export JAVA_HOME=${JAVA_HOME}` 修改为 `export JAVA_HOME=/usr/lib/java` ，即 Java 安装路径。

#### 2. 修改 `slaves`

文件 `slaves` 把里面的 `localhost` 改为 `slave1` `slave2` 。

#### 3. 修改 `core-site.xml`

修改为如下配置：


```xml
<configuration>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://master:9000</value>
        </property>
        <property>
                <name>hadoop.tmp.dir</name>
                <value>file:/usr/lib/hadoop/tmp</value>
                <description>Abase for other temporary directories.</description>
        </property>
</configuration>
```

#### 4. 修改 `hdfs-site.xml`

修改为如下配置：

```xml
<configuration>
        <property>
                <name>dfs.namenode.secondary.http-address</name>
                <value>master:50090</value>
        </property>
        <property>
                <name>dfs.replication</name>
                <value>2</value>
        </property>
        <property>
                <name>dfs.namenode.name.dir</name>
                <value>file:/usr/lib/hadoop/tmp/dfs/name</value>
        </property>
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>file:/usr/lib/hadoop/tmp/dfs/data</value>
        </property>
</configuration>
```

#### 5. 修改 `mapred-site.xml`

首先复制一份 `mapred-site.xml.template` 为 `mapred-site.xml` ，执行如下命令：

```shell
cp mapred-site.xml.template mapred-site.xml
```

然后修改为如下配置：

```xml
<configuration>
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.address</name>
                <value>master:10020</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.webapp.address</name>
                <value>master:19888</value>
        </property>
</configuration>
```

#### 6. 修改 `yarn-site.xml`

修改为如下配置：

```xml
<configuration>
        <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>master</value>
        </property>
        <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
        </property>
</configuration>
```

### 部署并运行 Hadoop


配置好后，将 master 上的 `/usr/lib/hadoop` 文件夹复制到各个 slave 节点上。在 master 节点上执行：

```shell
cd /usr/lib
tar -zcf ~/hadoop.master.tar.gz ./hadoop   # 先压缩再复制
scp ~/hadoop.master.tar.gz slave1:/home/hadoop
scp ~/hadoop.master.tar.gz slave2:/home/hadoop
```

分别在两个 slave 节点上执行：

```shell
sudo tar -zxf ~/hadoop.master.tar.gz -C /usr/lib
sudo chown -R hadoop /usr/lib/hadoop
```

安装完成后，首次启动需要先在 master 节点执行 `NameNode` 的格式化：

```shell
hdfs namenode -format # 首次运行需要执行初始化，之后不需要
```

成功的话，会看到 `successfully formatted` 和 `Exitting with status 0` 的提示，若为 `Exitting with status 1` 则是出错。

接着可以启动 `Hadoop` 和 `Yarn` 了，启动需要在 master 节点上进行：

```shell
start-dfs.sh
start-yarn.sh
mr-jobhistory-daemon.sh start historyserver
```

通过命令 `jps` 可以查看各个节点所启动的进程。正确的话，在 master 节点上应该可以看到 `NameNode`、`ResourceManager`、`SecondrryNameNode`、`JobHistoryServer` 进程。

::: details jps 查看进程
```shell{26-28}
> start-dfs.sh

Starting namenodes on [master]
master: starting namenode, logging to /usr/lib/hadoop/logs/hadoop-hadoop-namenode-master.out
slave2: starting datanode, logging to /usr/lib/hadoop/logs/hadoop-hadoop-datanode-slave2.out
slave1: starting datanode, logging to /usr/lib/hadoop/logs/hadoop-hadoop-datanode-slave1.out
Starting secondary namenodes [master]
master: starting secondarynamenode, logging to /usr/lib/hadoop/logs/hadoop-hadoop-secondarynamenode-master.out


> jps

1905 Jps
1267 NameNode
1495 SecondaryNameNode

> start-yarn.sh

starting yarn daemons
starting resourcemanager, logging to /usr/lib/hadoop/logs/yarn-hadoop-resourcemanager-master.out
slave1: starting nodemanager, logging to /usr/lib/hadoop/logs/yarn-hadoop-nodemanager-slave1.out
slave2: starting nodemanager, logging to /usr/lib/hadoop/logs/yarn-hadoop-nodemanager-slave2.out

> jps

1905 Jps
1267 NameNode
1495 SecondaryNameNode
```
:::

可以看到没有启动 `ResourceManager`，查看日志文件，日志文件的默认存放位置在 `${HADOOP_HOME}/logs` 下，因此进入 `/usr/lib/hadoop/logs`，查看 `yarn-hadoop-resourcemanager-master.log` 日志文件，发现如下错误：

```shell
Caused by: java.lang.reflect.InaccessibleObjectException: Unable to make protected final java.lang.Class java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain) throws java.lang.ClassFormatError accessible: module java.base does not "opens java.lang" to unnamed module @9efff14
```

查询后，发现问题为jdk版本过高，因此重新安装java环境，安装 `jdk-8u291-linux-x64.tar.gz` 版本，因此重新安装 Java 环境。

### 重新安装 Java 环境

在 Java 下载页面查看 Java archive 页面，选择 `Linux x64 | 185.16 MB | jdk-8u231-linux-x64.tar.gz`，本地下载。之后本地执行下述命令，要求pem文件和jdk文件在同一目录下，并在该目录打开终端，输入如下命令：

```shell
scp -i zjh-hadoop.pem jdk-8u231-linux-x64.tar.gz ubuntu@ec2-3-83-222-27.compute-1.amazonaws.com:/home/ubuntu/ 
scp -i zjh-hadoop.pem jdk-8u231-linux-x64.tar.gz ubuntu@ec2-54-175-170-160.compute-1.amazonaws.com:/home/ubuntu/
scp -i zjh-hadoop.pem jdk-8u231-linux-x64.tar.gz ubuntu@ec2-52-91-225-85.compute-1.amazonaws.com:/home/ubuntu/ 
```

删除原 Java 运行环境

```shell
sudo rm -rf /usr/lib/java -rf
```

复制到 hadoop 用户目录

```shell
sudo cp jdk-8u231-linux-x64.tar.gz  /home/hadoop/
```

解压部署

```shell
sudo tar -zxf /home/hadoop/jdk-8u231-linux-x64.tar.gz -C /usr/lib/   # 把JDK文件解压到/usr/lib目录下
sudo mv /usr/lib/jdk1.8.0_231  /usr/lib/java 
```

由于之前已经添加环境变量，因此这里不再继续添加，具体见 #[安装 java 环境](#安装-java-环境-jdk版本不匹配-正确安装见-重新安装-java-环境) 中的添加环境变量过程。

查看jdk版本

```shell
> java -version

java version "1.8.0_231"
Java(TM) SE Runtime Environment (build 1.8.0_231-b11)
Java HotSpot(TM) 64-Bit Server VM (build 25.231-b11, mixed mode)
```

### 重新运行 Hadoop

```shell
hadoop@master:/usr/lib/javastart-yarn.sh

starting yarn daemons
starting resourcemanager, logging to /usr/lib/hadoop/logs/yarn-hadoop-resourcemanager-master.out
slave1: starting nodemanager, logging to /usr/lib/hadoop/logs/yarn-hadoop-nodemanager-slave1.out
slave2: starting nodemanager, logging to /usr/lib/hadoop/logs/yarn-hadoop-nodemanager-slave2.out

hadoop@master:/usr/lib/javajps

1552 SecondaryNameNode
2485 ResourceManager
1324 NameNode
2735 Jps
```

可以看到成功运行了 `ResourceManager`，之后执行 `mr-jobhistory-daemon.sh start historyserver`，启动 `JobHistoryServer`。

```shell
hadoop@master:/usr/lib/javamr-jobhistory-daemon.sh start historyserver

starting historyserver, logging to /usr/lib/hadoop/logs/mapred-hadoop-historyserver-master.out

hadoop@master:/usr/lib/javajps

1552 SecondaryNameNode
2769 JobHistoryServer
2804 Jps
2485 ResourceManager
1324 NameNode
```

在 slave 节点可以看到 `DataNode` 和 `NodeManager` 进程，如下：

```shell
hadoop@slave1:/usr/lib/javajps

1194 DataNode
1659 NodeManager
1805 Jps
```

通过命令 `hdfs dfsadmin -report` 可查看集群状态，其中 `Live datanodes (2)` 表明两个从节点都已正常启动，如果是 `0` 则表示不成功：

::: details `hdfs dfsadmin -report` 命令结果
```shell
hadoop@master:/usr/lib/javahdfs dfsadmin -report

Configured Capacity: 30831288320 (28.71 GB)
Present Capacity: 22724452352 (21.16 GB)
DFS Remaining: 22724386816 (21.16 GB)
DFS Used: 65536 (64 KB)
DFS Used%: 0.00%
Under replicated blocks: 0
Blocks with corrupt replicas: 0
Missing blocks: 0
Missing blocks (with replication factor 1): 0
Pending deletion blocks: 0

-------------------------------------------------
Live datanodes (2):

Name: 172.31.82.238:50010 (slave2)
Hostname: slave2
Decommission Status : Normal
Configured Capacity: 15415644160 (14.36 GB)
DFS Used: 32768 (32 KB)
Non DFS Used: 4177514496 (3.89 GB)
DFS Remaining: 11221319680 (10.45 GB)
DFS Used%: 0.00%
DFS Remaining%: 72.79%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Thu Dec 14 13:00:07 UTC 2023


Name: 172.31.92.124:50010 (slave1)
Hostname: slave1
Decommission Status : Normal
Configured Capacity: 15415644160 (14.36 GB)
DFS Used: 32768 (32 KB)
Non DFS Used: 3895767040 (3.63 GB)
DFS Remaining: 11503067136 (10.71 GB)
DFS Used%: 0.00%
DFS Remaining%: 74.62%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Thu Dec 14 13:00:05 UTC 2023
```
:::



## 运行 Hadoop

### 查看 webUI

可以通过下列三个地址查看 webUI，其中 `ec2-xx-xxx-xxx-xx.us-west-2.compute.amazonaws.com` 是该实例的外部 DNS 主机名，`50070`、`8088`、`19888` 分别是 `hadoop`、`yarn`、`JobHistoryServer` 的默认端口，使用前需要开放对应端口。

### 运行 `hadoop-mapreduce-examples-*.jar`

```shell
hadoop fs -mkdir -p /user/hadoop   # 在hdfs上创建hadoop账户
hadoop fs -mkdir input
hadoop fs -put /usr/lib/hadoop/etc/hadoop/*.xml input  # 将hadoop配置文件复制到hdfs中
hadoop jar /usr/lib/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output 'dfs[a-z.]+'  # 运行实例
```

| 程序名称           | 用途                                                         |
| :---------------: | :----------------------------------------------------------: |
| aggregatewordcount | 一个基于聚合的map/reduce程序，它对输入文件中的单词进行计数。   |
| aggregatewordhist  | 一个基于聚合的map/reduce程序，用于计算输入文件中单词的直方图。 |
| bbp               | 一个使用Bailey Borwein Plouffe计算PI精确数字的map/reduce程序。 |
| dbcount           | 一个计算页面浏览量的示例作业，从数据库中计数。                 |
| distbbp           | 一个使用BBP型公式计算PI精确比特的map/reduce程序。              |
| grep              | 一个在输入中计算正则表达式匹配的map/reduce程序。               |
| join              | 一个影响连接排序、相等分区数据集的作业                       |
| multifilewc       | 一个从多个文件中计算单词的任务。                               |
| pentomino         | 一个地图/减少瓦片铺设程序来找到解决PotoMimo问题的方法。        |
| pi                | 一个用拟蒙特卡洛方法估计PI的MAP/Relp程序。                     |
| randomtextwriter  | 一个map/reduce程序，每个节点写入10GB的随机文本数据。           |
| randomwriter      | 一个映射/RADIUS程序，每个节点写入10GB的随机数据。             |
| secondarysort     | 定义一个次要排序到减少的例子。                                 |
| sort              | 一个对随机写入器写入的数据进行排序的map/reduce程序。           |
| sudoku            | 数独求解者。                                                 |
| teragen           | 为terasort生成数据                                            |
| terasort          | 运行terasort                                                 |
| teravalidate      | terasort的检查结果                                           |
| wordcount         | 一个映射/缩小程序，计算输入文件中的单词。                     |
| wordmean          | map/reduce程序，用于计算输入文件中单词的平均长度。             |
| wordmedian        | map/reduce程序，用于计算输入文件中单词的中值长度。             |


### 关闭 Hadoop

```shell
stop-yarn.sh
stop-dfs.sh
mr-jobhistory-daemon.sh stop historyserver
```
